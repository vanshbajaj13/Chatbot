{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpeHRAf-pzOA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A99onnTZpziu",
        "outputId": "1b9da8d0-50ce-448e-e59b-4f319f486735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot running\n",
            "hi\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "what can I do for you?\n",
            "What is the most sold Routers Model in india\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "what can I do for you?\n",
            "hello\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Hello\n",
            "What is the most sold Routers Model in india\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "what can I do for you?\n",
            "What is the most sold Routers Model in india\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "what can I do for you?\n",
            "bye\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "what can I do for you?\n"
          ]
        }
      ],
      "source": [
        "# Vansh bajaj 20BCE0772\n",
        "# Prateek aggarwal 20BCE0387\n",
        "# Swarit gupta 20BCI0320\n",
        "\n",
        "\n",
        "import random\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "# Load the pre-trained BERT model and tokenizer\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "\n",
        "# Define a function to generate responses to user queries\n",
        "def generate_response(query):\n",
        "    # Tokenize the input query\n",
        "    inputs = tokenizer.encode_plus(query, return_tensors='pt')\n",
        "    # Use the pre-trained BERT model to generate an answer\n",
        "    output = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "    start_scores = output.start_logits\n",
        "    end_scores = output.end_logits\n",
        "    start_index = torch.argmax(start_scores)\n",
        "    end_index = torch.argmax(end_scores) + 1\n",
        "    answer_tokens = inputs['input_ids'][0][start_index:end_index]\n",
        "    answer = tokenizer.decode(answer_tokens)\n",
        "    return answer\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "intents = json.loads(open('intents.json').read())\n",
        "\n",
        "words=pickle.load(open('words.pkl','rb'))\n",
        "classes=pickle.load(open('classes.pkl','rb'))\n",
        "\n",
        "model= load_model('my_chatbot.1.1')\n",
        "\n",
        "def clean_up_sentence (sentence):\n",
        "  sentence_words=nltk.word_tokenize(sentence)\n",
        "  sentence_words=[lemmatizer.lemmatize(word) for word in sentence_words]\n",
        "  return sentence_words\n",
        "\n",
        "def bg(sentence):\n",
        "  words=clean_up_sentence(sentence)\n",
        "  bag=[0]*len(words)\n",
        "  for w in words:\n",
        "    for i,word in enumerate(words):\n",
        "        if words==w:\n",
        "          bag[i]=1\n",
        "  return np.array(bag)\n",
        "\n",
        "def class_predict(sentence):\n",
        "  bow=bg(sentence)\n",
        "  res=model.predict(np.array([bow]))[0]\n",
        "  ERROR_THRESH=0.25\n",
        "  results=[[i,r] for i,r in enumerate(res) if r > ERROR_THRESH]\n",
        "\n",
        "  results.sort(key=lambda x:x[1],reverse=True)\n",
        "  return_list=[]\n",
        "  for r in  results:\n",
        "    return_list.append({'intent': classes[r[0]],'probability':str(r[1])})\n",
        "  return return_list\n",
        "\n",
        "def responses (intents_list,intents_json):\n",
        "  tag=intents_list[0]['intent']\n",
        "  list_of_intents=intents_json['intents']\n",
        "  for i in list_of_intents:\n",
        "    if i['tag']==tag:\n",
        "      result=random.choice(i['Responses'])\n",
        "      break\n",
        "  return result\n",
        "\n",
        "print(\"Chatbot started .......\")\n",
        "\n",
        "# Main loop to interact with the user\n",
        "while True:\n",
        "    # Get input from the user\n",
        "    query = input('User: ')\n",
        "    # Check if the user wants to exit\n",
        "    if query.lower() == 'exit':\n",
        "        print('Bot: Goodbye!')\n",
        "        break\n",
        "    # Generate a response using the BERT model\n",
        "    response = generate_response(query)\n",
        "    # Print the response\n",
        "    print('Bot: ' + response)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBi_tPebvX9A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
